# springboot-spring-kafka
## `> avro-serialization`

This sample demonstrates a **producer** that pushes `News` messages to a topic in `Kafka` and a **consumer** that listens those messages from `Kafka`
- Producer serializes the message `key` using `StringSerializer` and the message `value` using `AvroSerializer`;
- Consumer deserializes the message `key` using `StringDeserializer` and the message `value` using `AvroDeserializer`;
- We needed to implement `AvroSerializer` and `AvroDeserializer` classes;
- Producer creates the Kafka topics and Consumer doesn't.

## Start Environment

Before starting producer and consumer, the services present in `docker-compose.yml` file must be up and running as explained at [Start Environment](https://github.com/ivangfr/springboot-spring-kafka#start-environment) section of the main README

## Running applications using Maven

- **avro-producer-service**

  - Open a terminal navigate to `springboot-spring-kafka` root folder
  - Run application
    ```
    ./mvnw spring-boot:run --projects avro-serialization/avro-producer-service
    ```
    > The Java class `com.mycompany.avroproducerservice.avro.NewsMessage` is generated by the Avro file `news-message.avsc` present in `src/main/resources/avro` by running the command
    > ```
    > ./mvnw generate-sources --projects avro-serialization/avro-producer-service
    > ```
  - As soon as the producer is up and running, it will start pushing automatically and randomly `News` messages to `Kafka` topic `avro-serialization-news`. The default `delay` between messages is `3 seconds`.

- **avro-consumer-service**

  - Open another terminal and make sure you are in `springboot-spring-kafka` root folder
  - Run application
    ```
    ./mvnw spring-boot:run --projects avro-serialization/avro-consumer-service
    ```
    > The Java class `com.mycompany.avroconsumerservice.avro.NewsMessage` is generated by the Avro file `news-message.avsc` present in `src/main/resources/avro` by running the command
    > ```
    > ./mvnw generate-sources --projects avro-serialization/avro-consumer-service
    > ```
  - Once the consumer is up and running, it will start listening `News` messages from the `Kafka` topic `avro-serialization-news`

## Running applications as Docker containers

- ### Build Docker images

  - Open a terminal navigate to `springboot-spring-kafka` root folder
  - Run the following script to build the images
    - JVM
      ```
      ./docker-build.sh avro-serialization
      ```
    - Native (it's not implemented yet)
      ```
      ./docker-build.sh avro-serialization native
      ```

- ### Environment variables

  **avro-producer-service** and **avro-consumer-service**

  | Environment Variable | Description                                                             |
  | -------------------- | ----------------------------------------------------------------------- |
  | `KAFKA_HOST`         | Specify host of the `Kafka` message broker to use (default `localhost`) |
  | `KAFKA_PORT`         | Specify port of the `Kafka` message broker to use (default `29092`)     |

- ### Run Docker containers

  - **avro-producer-service**

    In a terminal, run the following Docker command
    ```
    docker run --rm --name avro-producer-service -p 9084:9084 \
      -e KAFKA_HOST=kafka -e KAFKA_PORT=9092 \
      --network=springboot-spring-kafka_default \
      docker.mycompany.com/avro-producer-service:1.0.0
    ```

  - **avro-consumer-service**

    In another terminal, run the Docker command below
    ```
    docker run --rm --name avro-consumer-service -p 9085:9085 \
      -e KAFKA_HOST=kafka -e KAFKA_PORT=9092 \
      --network=springboot-spring-kafka_default \
      docker.mycompany.com/avro-consumer-service:1.0.0
    ```
  
## Shutdown

Go to the terminals where the applications are running and press `Ctrl+C`
